import os
import sys
import termios
import fcntl
import yaml
import torch
import torch_scatter
import imageio
import copy
import numpy as np
import re
import time
import signal
from queue import Queue,Empty  # æ–°å¢ï¼šçº¿ç¨‹å®‰å…¨é˜Ÿåˆ—
from tqdm import tqdm
from argparse import ArgumentParser, Namespace

sys.path.append(os.path.dirname(os.path.dirname(os.path.realpath(__file__))))
from internal.utils.general_utils import parse
from internal.utils.render_utils import generate_path, record_path, generate_static_path, generate_path_custom, generate_single_pose, pad_poses
from internal.utils.gaussian_model_loader import GaussianModelLoader

import threading
import socket
import cv2

# --------------------------
# å…¨å±€å˜é‡ï¼ˆæ–°å¢é˜Ÿåˆ—ï¼‰
# --------------------------
offset = {'x': 0.0, 'y': 0.0, 'z': 0.0}
offset_lock = threading.Lock()
# æ–°å¢è§’åº¦æ§åˆ¶å˜é‡
yaw = 0.0         # åèˆªè§’
pitch = 0.0       # ä¿¯ä»°è§’
roll = 0.0        # ç¿»æ»šè§’
angle_lock = threading.Lock()  # è§’åº¦æ§åˆ¶çš„çº¿ç¨‹é”
STEP = 0.1
STEP_ANGLE = 1.0  # è§’åº¦å˜åŒ–æ­¥é•¿ï¼ˆ10åº¦ï¼‰
KEYBOARD_THREAD_RUNNING = True
SEND_THREAD_RUNNING = True  # å‘é€çº¿ç¨‹è¿è¡Œæ ‡å¿—
old_terminal_attr = None
IMAGE_QUEUE = Queue(maxsize=3)  # å›¾åƒç¼“å†²é˜Ÿåˆ—ï¼ˆæœ€å¤§5å¼ ï¼Œé¿å…å†…å­˜å †ç§¯ï¼‰

# --------------------------
# ç»ˆç«¯æ¨¡å¼åˆ‡æ¢å·¥å…·å‡½æ•°
# --------------------------
def set_terminal_raw_mode():
    global old_terminal_attr
    fd = sys.stdin.fileno()
    old_terminal_attr = termios.tcgetattr(fd)
    new_attr = termios.tcgetattr(fd)
    new_attr[3] &= ~(termios.ICANON | termios.ECHO)
    termios.tcsetattr(fd, termios.TCSANOW, new_attr)
    fcntl.fcntl(fd, fcntl.F_SETFL, os.O_NONBLOCK)
    return old_terminal_attr

def restore_terminal_mode():
    global old_terminal_attr
    if old_terminal_attr is not None:
        fd = sys.stdin.fileno()
        termios.tcsetattr(fd, termios.TCSANOW, old_terminal_attr)
        old_terminal_attr = None

# --------------------------
# ä¿¡å·å¤„ç†å‡½æ•°
# --------------------------
def handle_sigint(signum, frame):
    print("\nğŸ›‘ æ•è·åˆ°Ctrl+Cï¼Œæ­£åœ¨é€€å‡º...")
    global KEYBOARD_THREAD_RUNNING, SEND_THREAD_RUNNING
    KEYBOARD_THREAD_RUNNING = False
    SEND_THREAD_RUNNING = False
    restore_terminal_mode()
    # å‘é˜Ÿåˆ—æ”¾å…¥Noneä½œä¸ºé€€å‡ºä¿¡å·
    IMAGE_QUEUE.put(None)
    sys.exit(0)

signal.signal(signal.SIGINT, handle_sigint)

# --------------------------
# é”®ç›˜ç›‘å¬çº¿ç¨‹ï¼ˆæ–°å¢è§’åº¦æ§åˆ¶ï¼‰
# --------------------------
def keyboard_listener_thread():
    # æ›´æ–°æç¤ºä¿¡æ¯ï¼ŒåŒ…å«è§’åº¦æ§åˆ¶æŒ‰é”®
    print("é”®ç›˜ç›‘å¬çº¿ç¨‹å·²å¯åŠ¨ï¼ˆæŒ‰W/S/A/D/Q/Eæ§åˆ¶åç§»ï¼›J/L/I/K/U/Oæ§åˆ¶è§’åº¦ï¼›æŒ‰Ctrl+Cé€€å‡ºï¼‰")
    set_terminal_raw_mode()
    try:
        while KEYBOARD_THREAD_RUNNING:
            try:
                key = sys.stdin.read(1)
                if not key:
                    time.sleep(0.01)
                    continue
                key = key.lower()
                
                # ä½ç½®åç§»æ§åˆ¶ï¼ˆåŸæœ‰é€»è¾‘ï¼‰
                with offset_lock:
                    if key == 'w':
                        offset['x'] += STEP
                        print(f"âœ… X+ åç§»é‡æ›´æ–°ï¼š{offset['x']:.2f}")
                    elif key == 's':
                        offset['x'] -= STEP
                        print(f"âœ… X- åç§»é‡æ›´æ–°ï¼š{offset['x']:.2f}")
                    elif key == 'a':
                        offset['y'] += STEP
                        print(f"âœ… Y+ åç§»é‡æ›´æ–°ï¼š{offset['y']:.2f}")
                    elif key == 'd':
                        offset['y'] -= STEP
                        print(f"âœ… Y- åç§»é‡æ›´æ–°ï¼š{offset['y']:.2f}")
                    elif key == 'q':
                        offset['z'] -= STEP
                        print(f"âœ… Z- åç§»é‡æ›´æ–°ï¼š{offset['z']:.2f}")
                    elif key == 'e':
                        offset['z'] += STEP
                        print(f"âœ… Z+ åç§»é‡æ›´æ–°ï¼š{offset['z']:.2f}")
                
                # æ–°å¢è§’åº¦æ§åˆ¶é€»è¾‘
                with angle_lock:
                    if key == 'j':  # ç›¸æœºå‘å·¦æ—‹
                        global roll
                        roll -= STEP_ANGLE
                        print(f"ğŸ”„ Roll- è§’åº¦æ›´æ–°ï¼š{roll:.1f}Â°")
                    elif key == 'l':  # ç›¸æœºå‘å³æ—‹
                        roll += STEP_ANGLE
                        print(f"ğŸ”„ Roll+ è§’åº¦æ›´æ–°ï¼š{roll:.1f}Â°")
                    elif key == 'i':  # ç›¸æœºå‘ä¸Šç¿»
                        global pitch
                        pitch += STEP_ANGLE
                        print(f"ğŸ”„ Pitch+ è§’åº¦æ›´æ–°ï¼š{pitch:.1f}Â°")
                    elif key == 'k':  # ç›¸æœºå‘ä¸‹ç¿»
                        pitch -= STEP_ANGLE
                        print(f"ğŸ”„ Pitch- è§’åº¦æ›´æ–°ï¼š{pitch:.1f}Â°")
                    elif key == 'u':  # ç›¸æœºå‘å·¦ç¿»
                        global yaw
                        yaw -= STEP_ANGLE
                        print(f"ğŸ”„ Yaw- è§’åº¦æ›´æ–°ï¼š{yaw:.1f}Â°")
                    elif key == 'o':  # ç›¸æœºå‘å³ç¿»
                        yaw += STEP_ANGLE
                        print(f"ğŸ”„ Yaw+ è§’åº¦æ›´æ–°ï¼š{yaw:.1f}Â°")
                        
                        
            except Exception:
                continue
    finally:
        restore_terminal_mode()

# --------------------------
# å‘é€çº¿ç¨‹ï¼ˆä¿®å¤é˜»å¡é€€å‡ºï¼‰
# --------------------------
def send_thread(port=12345):
    """é•¿æœŸè¿è¡Œçš„å‘é€çº¿ç¨‹ï¼Œä½¿ç”¨é•¿è¿æ¥æŒç»­å‘é€å›¾åƒï¼ˆä¿®å¤é€€å‡ºé€»è¾‘ï¼‰"""
    print(f"å‘é€çº¿ç¨‹å·²å¯åŠ¨ï¼ˆç«¯å£ {port}ï¼‰ï¼Œç­‰å¾…å›¾åƒæ•°æ®...")
    # æ–°å¢ï¼šä¿å­˜å½“å‰è¿æ¥çš„socketï¼Œç”¨äºé€€å‡ºæ—¶å¼ºåˆ¶å…³é—­
    current_socket = None
    current_conn = None

    while SEND_THREAD_RUNNING:
        try:
            with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
                current_socket = s  # è®°å½•å½“å‰socket
                s.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
                s.bind(('0.0.0.0', port))
                s.settimeout(1.0)  # ç¼©çŸ­è¶…æ—¶ï¼ŒåŠ å¿«é€€å‡ºå“åº”
                s.listen(1)
                print("ç­‰å¾…æ¥æ”¶ç«¯è¿æ¥...")
                
                try:
                    conn, addr = s.accept()
                    current_conn = conn  # è®°å½•å½“å‰è¿æ¥
                    print(f"å·²ä¸æ¥æ”¶ç«¯ {addr} å»ºç«‹é•¿è¿æ¥")
                except socket.timeout:
                    continue  # è¶…æ—¶åé‡æ–°å¾ªç¯ï¼Œæ£€æŸ¥æ˜¯å¦éœ€è¦é€€å‡º

                with conn:
                    while SEND_THREAD_RUNNING:  # ä¾èµ–SEND_THREAD_RUNNINGé€€å‡º
                        try:
                            image = IMAGE_QUEUE.get(timeout=0.05)
                            if image is None:
                                break
                            
                            img_bgr = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)
                            _, img_encoded = cv2.imencode('.jpg', img_bgr, [int(cv2.IMWRITE_JPEG_QUALITY), 80])
                            img_bytes = img_encoded.tobytes()
                            conn.sendall(len(img_bytes).to_bytes(4, byteorder='big'))
                            conn.sendall(img_bytes)
                            IMAGE_QUEUE.task_done()
                        except Empty:
                            continue
                        except Exception as e:
                            print(f"é•¿è¿æ¥å‘é€é”™è¯¯ï¼š{str(e)}ï¼Œå°è¯•é‡è¿...")
                            break
        except Exception as e:
            print(f"è¿æ¥å»ºç«‹å¤±è´¥ï¼š{str(e)}ï¼Œ1ç§’åé‡è¯•...")
            time.sleep(1)
            continue
        finally:
            # é€€å‡ºå‰å¼ºåˆ¶å…³é—­è¿æ¥ï¼Œé¿å…é˜»å¡
            if current_conn:
                try:
                    current_conn.close()
                except:
                    pass
            if current_socket:
                try:
                    current_socket.close()
                except:
                    pass

    print("å‘é€çº¿ç¨‹ï¼šå·²é€€å‡º")

# --------------------------
# å…¶ä»–å·¥å…·å‡½æ•°ï¼ˆä¸å˜ï¼‰
# --------------------------
def voxel_filtering_no_gt(voxel_size, xy_range, target_xyz, std_ratio=2.0):
    assert len(xy_range) == 4, "Unrecognized xy_range format"
    with torch.no_grad():
        voxel_index = torch.div(torch.tensor(target_xyz[:, :2]).float() - xy_range[None, :2], voxel_size[None, :], rounding_mode='floor')
        voxel_coords = voxel_index * voxel_size[None, :] + xy_range[None, :2] + voxel_size[None, :] / 2
        new_coors, unq_inv, unq_cnt = torch.unique(voxel_coords, return_inverse=True, return_counts=True, dim=0)
        feat_mean = torch_scatter.scatter(target_xyz[:, 2], unq_inv, dim=0, reduce='mean')
        feat_std = torch_scatter.scatter_std(target_xyz[:, 2], unq_inv, dim=0)
        mask = target_xyz[:, 2] > feat_mean[unq_inv] + std_ratio * feat_std[unq_inv]
    return mask

def get_next_video_path(base_path):
    if not os.path.exists(base_path):
        return base_path
    dir_name = os.path.dirname(base_path)
    base_name = os.path.basename(base_path)
    name_without_ext, ext = os.path.splitext(base_name)
    pattern = re.compile(rf'^{re.escape(name_without_ext)}_(\d+){re.escape(ext)}$')
    existing_numbers = []
    if os.path.exists(dir_name):
        for filename in os.listdir(dir_name):
            match = pattern.match(filename)
            if match:
                existing_numbers.append(int(match.group(1)))
    next_number = max(existing_numbers) + 1 if existing_numbers else 1
    new_filename = f"{name_without_ext}_{next_number:03d}{ext}"
    return os.path.join(dir_name, new_filename)

# --------------------------
# ä¸»ç¨‹åºï¼ˆä¿®æ”¹å›¾åƒå‘é€é€»è¾‘ï¼‰
# --------------------------
if __name__ == "__main__":
    # å‚æ•°è§£æï¼ˆä¸å˜ï¼‰
    parser = ArgumentParser(description="Training script parameters")
    parser.add_argument('--output_path', type=str, help='path of config', default=None)
    parser.add_argument('--data_path', type=str, help='path of data', default=None)
    parser.add_argument("--n_frames", type=int, default=240)
    parser.add_argument("--train", action="store_true")
    parser.add_argument("--scale_percentile", type=int, default=99)
    parser.add_argument("--pitch", type=float, default=None)
    parser.add_argument("--x_shift", type=float, default=0)
    parser.add_argument("--y_shift", type=float, default=0)
    parser.add_argument("--quiet", action="store_true")
    parser.add_argument("--filter", action="store_true")
    parser.add_argument("--vox_grid", type=int, default=25)
    parser.add_argument("--std_ratio", type=float, default=2.0)
    parser.add_argument("--save_filtered_gs", action="store_true")
    parser.add_argument("--custom", action="store_true")
    parser.add_argument("--single_image", action="store_true")
    parser.add_argument("--x_offset", type=float, default=0.0)
    parser.add_argument("--y_offset", type=float, default=0.0)
    parser.add_argument("--z_offset", type=float, default=0.0)
    parser.add_argument("--pitch_single", type=float, default=0.0)
    parser.add_argument("--yaw_single", type=float, default=0.0)
    parser.add_argument("--roll_single", type=float, default=0.0)
    args = parser.parse_args(sys.argv[1:])

    # åŠ è½½æ¨¡å‹ä¸æ•°æ®ï¼ˆä¸å˜ï¼‰
    loadable_file = GaussianModelLoader.search_load_file(args.output_path)
    ckpt = torch.load(loadable_file, map_location="cpu")
    dataparser_config = ckpt["datamodule_hyper_parameters"]["parser"]
    data_path = args.data_path if args.data_path else ckpt["datamodule_hyper_parameters"]["path"]
    dataparser_outputs = dataparser_config.instantiate(
        path=data_path, output_path=os.getcwd(), global_rank=0
    ).get_outputs()
    cameras = dataparser_outputs.train_set.cameras if args.train else dataparser_outputs.test_set.cameras
    device = torch.device("cuda")
    bkgd_color = torch.tensor(ckpt["hyper_parameters"]["background_color"], device=device)
    model = GaussianModelLoader.initialize_model_from_checkpoint(ckpt, device=device)
    model.freeze()
    model.pre_activate_all_properties()
    renderer = GaussianModelLoader.initialize_renderer_from_checkpoint(ckpt, stage="validate", device=device)
    print(f"Gaussian count: {model.get_xyz.shape[0]}")
    traj_dir = os.path.join(ckpt["datamodule_hyper_parameters"]["path"], 'traj')
    os.makedirs(traj_dir, exist_ok=True)

    # å¾ªç¯æ¸²æŸ“+é”®ç›˜æ§åˆ¶é€»è¾‘
    if args.single_image:
        # 1. è®¡ç®—åŸºå‡†ä½å§¿
        first_cam_pose = np.linalg.inv(np.asarray((cameras[0].world_to_camera.T).cpu().numpy()))
        first_cam_pose = np.diag([1, -1, 1, 1]) @ first_cam_pose
        print("\nğŸ“Œ å·²è®°å½•åŸºå‡†ä½å§¿ï¼Œå¼€å§‹å¾ªç¯æ¸²æŸ“ï¼ˆæŒ‰Ctrl+Cç»ˆæ­¢ï¼‰")
        
        # 2. å¯åŠ¨é”®ç›˜çº¿ç¨‹å’Œå‘é€çº¿ç¨‹ï¼ˆå‘é€çº¿ç¨‹é•¿æœŸè¿è¡Œï¼‰
        keyboard_thread = threading.Thread(target=keyboard_listener_thread, daemon=True)
        keyboard_thread.start()
        
        send_thread_obj = threading.Thread(target=send_thread, args=(12345,), daemon=True)
        send_thread_obj.start()

        try:
            while True:
                # 3. è·å–åç§»é‡å’Œè§’åº¦
                with offset_lock:
                    current_x = offset['x']
                    current_y = offset['y']
                    current_z = offset['z']
                with angle_lock:
                    current_yaw = yaw
                    current_pitch = pitch
                    current_roll = roll

                # 4. ç”Ÿæˆä½å§¿+æ„é€ ç›¸æœºï¼ˆä½¿ç”¨å®æ—¶è§’åº¦ï¼‰
                single_pose = generate_single_pose(
                    reference_pose=first_cam_pose,
                    x_offset=current_x,
                    y_offset=current_y,
                    z_offset=current_z,
                    yaw=current_yaw,  # ä½¿ç”¨å®æ—¶yaw
                    pitch=current_pitch,  # ä½¿ç”¨å®æ—¶pitch
                    roll=current_roll  # ä½¿ç”¨å®æ—¶roll
                )
                single_pose = pad_poses(np.array([single_pose]))[0]

                #åŸä»£ç 
                cam = copy.deepcopy(cameras[0]).to_device("cuda")
                cam.height = int(cam.height / 2) * 2
                cam.width = int(cam.width / 2) * 2
                c2w = single_pose @ np.diag([1, -1, -1, 1])
                cam.world_to_camera = torch.from_numpy(np.linalg.inv(c2w).T).float().cuda()
                cam.full_projection = (cam.world_to_camera.unsqueeze(0).bmm(cam.projection.unsqueeze(0))).squeeze(0)
                cam.camera_center = cam.world_to_camera.inverse()[3, :3]

                # 5. æ¸²æŸ“
                img = renderer(cam, model, bkgd_color)['render']
                img = (img * 255).clamp(0, 255).to(torch.uint8).permute(1, 2, 0).cpu().numpy()

                # æ–°å¢ï¼šç¼©å°å›¾åƒå°ºå¯¸ï¼ˆå…³é”®ä¼˜åŒ–ï¼‰
                # ä¾‹å¦‚ï¼šç¼©å°åˆ°åŸå°ºå¯¸çš„50%ï¼ˆæ ¹æ®éœ€æ±‚è°ƒæ•´scaleå€¼ï¼‰
                scale = 0.95  # ç¼©æ”¾æ¯”ä¾‹ï¼ˆå›¾ç‰‡è´¨é‡å¤ªå¤§ï¼‰
                height, width = img.shape[:2]
                new_height = int(height * scale)
                new_width = int(width * scale)
                # ä½¿ç”¨INTER_AREAæ’å€¼ï¼Œç¼©å°å›¾åƒæ—¶è´¨é‡æ›´ä¼˜
                img = cv2.resize(img, (new_width, new_height), interpolation=cv2.INTER_AREA)


                # æ‰“å°ä¿¡æ¯ï¼ŒåŒ…å«è§’åº¦
                frame_count = 0  # åœ¨å¾ªç¯å¤–å®šä¹‰
                frame_count += 1
                if frame_count % 25 == 0:  # æ¯25å¸§æ‰“å°ä¸€æ¬¡
                    print(f"[{time.ctime()}] æ¸²æŸ“å®Œæˆï¼ˆä½ç½®ï¼šX={current_x:.2f}, Y={current_y:.2f}, Z={current_z:.2f}ï¼›è§’åº¦ï¼šYaw={current_yaw:.1f}Â°, Pitch={current_pitch:.1f}Â°, Roll={current_roll:.1f}Â°ï¼‰")

                # 6. å°†å›¾åƒæ”¾å…¥é˜Ÿåˆ—ï¼ˆè€Œéåˆ›å»ºæ–°çº¿ç¨‹ï¼‰
                if not IMAGE_QUEUE.full():
                    IMAGE_QUEUE.put(img)  # é˜Ÿåˆ—æœªæ»¡åˆ™æ”¾å…¥
                    # print("å›¾åƒå·²åŠ å…¥å‘é€é˜Ÿåˆ—")
                else:
                    print("âš ï¸  å‘é€é˜Ÿåˆ—å·²æ»¡ï¼Œä¸¢å¼ƒå½“å‰å›¾åƒ")

                # å…³é”®ï¼šç¼©çŸ­å»¶è¿Ÿè‡³0.02ç§’ï¼ˆç†è®ºæ”¯æŒ50fpsï¼Œé¢„ç•™æ¸²æŸ“æ—¶é—´ï¼‰
                # è‹¥æ¸²æŸ“è€—æ—¶è¾ƒé•¿ï¼Œå¯å»æ‰å›ºå®šå»¶è¿Ÿï¼Œè®©å¾ªç¯è‡ªç„¶ç”±æ¸²æŸ“æ—¶é—´æ§åˆ¶
                #time.sleep(0.02)

        finally:
            # 1. ä¿®æ­£ï¼šå°†å‘é€çº¿ç¨‹è¿è¡Œæ ‡å¿—è®¾ä¸ºFalse
            KEYBOARD_THREAD_RUNNING = False
            SEND_THREAD_RUNNING = False  # å…³é”®ä¿®å¤ï¼šæ”¹ä¸ºFalse
            # 2. å‘é˜Ÿåˆ—æ”¾å…¥é€€å‡ºä¿¡å·
            IMAGE_QUEUE.put(None)
            # 3. ç­‰å¾…é”®ç›˜çº¿ç¨‹å’Œå‘é€çº¿ç¨‹å®Œå…¨é€€å‡º
            keyboard_thread.join(timeout=2.0)  # é™æ—¶ç­‰å¾…
            send_thread_obj.join(timeout=2.0)   # æ–°å¢ï¼šç­‰å¾…å‘é€çº¿ç¨‹
            # 4. æ¢å¤ç»ˆç«¯
            restore_terminal_mode()
            print("æ‰€æœ‰çº¿ç¨‹å·²é€€å‡ºï¼Œç¨‹åºç»ˆæ­¢")